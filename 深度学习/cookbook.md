# 面向开发者的提示词工程

学习cookbook，基于吴恩达老师的《Prompt Engineering for Developer》课程

LLM分为两种类型：**基础LLM** 与**指令微调LLM**

**基础LLM**是基于文本训练数据，训练出预测下一个单词能力的模型。其通常通过在互联网和其他来源的大量数据上训练，来确定紧接着出现的最可能的词。

**指令微调 LLM** 通过专门的训练，可以更好地理解并遵循指令。指令微调 LLM 的训练通常基于预训练语言模型，先在大规模文本数据上进行**预训练**，掌握语言的基本规律。在此基础上进行进一步的训练与**微调（finetune）**，输入是指令，输出是对这些指令的正确回复。有时还会采用**RLHF（reinforcement learning from human feedback，人类反馈强化学习）**技术，根据人类对模型输出的反馈进一步增强模型遵循指令的能力。通过这种受控的训练过程。指令微调 LLM 可以生成对指令高度敏感、更安全可靠的输出，较少无关和损害性内容。因此。许多实际应用已经转向使用这类大语言模型。

## 提示原则

> 设计高效 Prompt 的两个关键原则：**编写清晰、具体的指令**和**给予模型充足思考时间**。

### 原则一

prompt需要清晰明确地表达需求 提供充足上下文 使语言模型准确理解我们的意图

#### 1使用分隔符清晰地表示输入的不同部分

可以选择用 ````，"""，< >，<tag> </tag>，:` 等做分隔符，只要能明确起到隔断作用即可。

使用分隔符尤其重要的是可以防止 **提示词注入（Prompt Rejection）**

#### 2寻求结构化的输出]寻求结构化的输出

有时候我们需要语言模型给我们一些结构化的输出 不仅仅是连续的文本



### 原则二

 Prompt 应加入逐步推理的要求，给模型留出充分思考时间，这样生成的结果才更准确可靠

