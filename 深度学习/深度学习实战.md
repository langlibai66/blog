### 看完李沐的视频后，希望将所有练习竞赛进行一遍

## 波士顿房价预测

### 首先进行数据预处理

### 数据预处理先将训练集测试集合并，主要进行正规化，处理缺失值，将str转化为独热编码，然后将训练集的target进行单独保存

### 确定loss

##### nn库，例如nn.MSEloss()

### 搭建net

##### 使用nn.Sequential作为容器开始搭建，同样使用nn

### 构建train函数

##### 传入参数 输入  标签 测试输入 

##### 传入超参learning_rate,epochs, batch_size，weight_decay

##### 使用迭代器

##### 传入后构建优化器，optimizer

###### torch.clamp的作用是将值限制在一定范围内

```python
import torch
from torch import nn
# x_train = x_train.drop('Id',axis=1)
input_size  = x_train.shape[1]
hidden_size = 10
output_size = 1
batch_size = 128
neu = nn.Sequential(
    nn.Linear(input_size,hidden_size),
    nn.ReLU(),
    nn.Linear(hidden_size,hidden_size),
    nn.ReLU(),
    nn.Linear(hidden_size,output_size)
)
loss = nn.MSELoss()
optimizer = torch.optim.Adam(neu.parameters(),lr=0.001)
losses = []
loss_a = []
y_train = train_data['Sold Price']
for i in range(0,len(x_train),batch_size):
    x = torch.tensor(x_train[i:i+batch_size].values,dtype=torch.float32)
    y = torch.tensor(y_train[i:i+batch_size].values,dtype=torch.float32).view(-1,1)
    y_pred = neu(x)
    l = loss(y_pred,y)
    losses.append(l.item())
    optimizer.zero_grad()
    l.backward()
    optimizer.step()
    if i % 1000 == 0:
        print(i)
        loss_a.append(sum(losses)/len(losses))
        losses = []
import matplotlib.pyplot as plt
plt.plot(loss_a)
plt.show()

```

再简单不过的一次练习就完成了