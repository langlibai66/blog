# stGCF笔记

针对论文

## 音频测量方法

为了在相同的状态空间中集成多模态线索 我们首先需要将音频线索映射到与视觉线索相同的定位平面

### stGCF

首先我们确定

一般形式的GCF

![image-20240409211117361](C:\Users\86186\AppData\Roaming\Typora\typora-user-images\image-20240409211117361.png)

我们为了构建模拟真实空间，利用针孔摄像机模型将2d点投影到三维世界坐标中的3d点，深度是指从3D点到相机光学中心的垂直距离（针孔相机模型其实是说了成像的模拟过程把深度都考虑到了，可以确定空间位置）

经过映射后的点为

![image-20240409211629926](C:\Users\86186\AppData\Roaming\Typora\typora-user-images\image-20240409211629926.png)

此时GCF的输出结构为

![image-20240409211648358](C:\Users\86186\AppData\Roaming\Typora\typora-user-images\image-20240409211648358.png)

矩阵中的每一个元素对于R(t,P)来说都是短时的，所以我们猜想

### Siamese网络

此网络大致是用语评估两个目标之间的相似度的，这是一种特殊的架构 由两个相同结构的子网络组成，两个子网络共享参数 

输入是待比较两个对象（例如 第一帧中的目标与视频帧中的搜索区域） 

输出是链各个输入对象之间的相似度的向量或标量

在进行网络改良工作前，我想先将GCF与各种CNN网络结合的办法进行总结学习
# GCF
GCF作为我们的听觉生成似然函数  能够较好的描述声源空间分布的概率。相比于基于单对麦克风所计算的GCC-PHAT 函数容易受噪声影响，出现峰值偏离声源真实位置的情况，GCF 函数结合了不同麦克风对之间的 GCC-PHAT 函数，具有更强的鲁棒性。
GCF 图是定义在 3D 空间中的函数
*（同一高度平面上，不同距离对应的 GCF 函数值相差也不大，即 GCF 函数在声源水平转向角方向较为敏感，在距离和俯仰角方向不敏感。）*
# DL
近年来，人工智能取得了重大进展。它具有广泛的应用，这导致了它在科学领域的巨大影响。声学检测和定位也是这样一个领域
CNN 是一种深度学习算法，可以获取输入图像，为图像中的不同对象分配权重，并且能够相互区分[98]。一种基于DoA参数估计的方法。采用接收信号短时傅里叶变换(STFT)系数的相位分量作为输入数据，训练包括学习DoA估计所需的特征。这种方法被证明可以有效地适应前所未有的声学条件
提出使用相位图来估计 DoA 参数。在基于 CNN 的声学定位中，相位图可视化了两个音频信号之间的相位差，这是一对拾取的麦克风。通过计算信号之间的相位差，可以估计声源到达方向(DoA)。相位图通常用作 CNN 的输入特征，允许网络学习将某些相位模式与声源的方向相关联。
另一种有趣的解决方案，他们使用CNN根据频谱图对对象进行分类
频谱图是音频信号随时间频率内容的视觉表示。通过处理音频信号的频谱图，CNN 可以学习识别与特定对象或声音相对应的频域中的模式。我们的任务主要就是对频谱图进行处理
记得找
![在这里插入图片描述](https://gitee.com/ai-yang-chenxu/img/raw/master/img/f4606b61453d4e4ca39531204d1b7067.png)
transformer是一种非常擅长处理数据序列的方法，非常适合设计随着时间的推移分析音频的任务，与基于 CNN 的方法相比，基于注意力的模型可以显着提高方位角


当对训练数据训练的网络在测试数据上进行评估时，可以观察到网络性能的下降。这是深度学习的一个众所周知的效果，因为当测试数据和训练数据之间存在显着不匹配时无法泛化。这个问题在声源检测和定位中尤其重要，其中开发大型、标记和可靠的数据集很困难。然而，大多数作者声称他们获得了良好的结果，这意味着神经网络是检测和定位声源的强大工具，提供了高性能和适应性。

相对于经典算法的显著优势之一是它们能够通过获取新数据来持续学习和改进。与通常依赖于预定义规则和固定参数的静态经典算法不同



我们拥有sample3d （9,11520,3）

我们现在可以加上我们的max_map_v        (11520)

根据argmax的计算

将两者合成为max_gcf_pc (11520,4)







































STGCF代码：

首先对序列进行遍历

​	加载音频对应的GCC data

​	循环摄像机

​		获取对应的GCC

​		获取对应的图像帧的开始与结束位置

​		获取图像路径（无必要）与标注文件（label）

​		加载图像数据

​		初始化计算所需要的变量

​		逐帧处理图像数据并计算误差

​			计算gt点

​			进行GCFmap的获取

​			计算误差



seq08

cam1 20         549		                               27          |54|                 （506）              513           {545}                    452

cam2  0          529                                                      |34|                （486）				525									   452

cam3  10        539                                        28         |44|                （496）            {535}                







seq 08的开始

开始                                     是1的34					

开始                                    是2的14

开始                                  是3的24



结束                                是1的515	

结束                                是2的495

结束								是3的505





​													



seq 11的开始

71                                     是1的71					

70                                     是2的69

101                                   是3的100



结束                                是1的549	

结束                                是2的547

结束								是3的678



seq 12的开始

71                                     是1的90					

70                                     是2的124

101                                   是3的88



结束                                是1的	1150

结束                                是2的     1184

结束								是3的	 1148







seq12          

cam1         2              {90}                            {1150}                           90                                              1115

cam2        37             {124}                           {1184}                        125                                             1150

cam3         0               {105}                           {1148}                         88                                                1113



seq12 gt  

cam                                                                                                       88                                              1113

​																											 123							                  1148

​																										      86									           1111





























将三维坐标定位，投影到三个平面上，将loss做总和



先进行投影，将二维坐标定位，各做各的









基于二维投影的方法，使得CV的很多网络可以应用

三维体素方法（排除，因为栅格没用）

图卷积神经网络





从稀疏点云中寻找高密度的表示







基于投影的方法将非结构化的三维点云**投影到特定的预设模态**中(例如体素、柱状体)

**MVCNN**

**Volumetric**





点云目标检测

**multi-view** method，**projection-based** method，**point-based** method







协同训练，即通过交替训练的方式使未标记的两个不同视图的相互一致性最大化；多核学习是通过利用与不同视图自然对应的内核进行线性或非线性的组合以提高学习性能；子空间学习是通过假设输入视角是从多个视角共享的子空间产生的。当然，除了上述的三类多视角融合算法外，还有包括集成学习、迁移学习、CNN、RNN等常用方法。













三维数据定位   迭代一次  loss 三个的总和











# 切记，我在做多视角融合，我的结果必须是 使用其他点的辅助信息让我每个点都定位的更准了

# 而不是仅仅使用更多点让他更准了

